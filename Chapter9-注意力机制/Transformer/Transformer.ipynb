{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e346dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc895aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Part: Token Embedding\n",
    "class TokenEmbedding(nn.Embedding):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__(vocab_size, d_model, padding_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df50a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Part: Positional Embedding\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, max_len, d_model):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # P.shape -> (batch_size, max_len, d_model)\n",
    "        self.P = torch.zeros(size=(1, max_len, d_model))\n",
    "        # pos_matrix.shape -> (max_len, 1)\n",
    "        pos_matrix = torch.arange(0, max_len, dtype=torch.float32).reshape((-1, 1))\n",
    "        # div_matrix.shape -> (1, d_model / 2)\n",
    "        div_matrix = torch.pow(10000, torch.arange(0, d_model, 2, dtype=torch.float32) / d_model)\n",
    "        # X.shape -> (max_len, d_model / 2)\n",
    "        X = pos_matrix / div_matrix\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "    def forward(self, X):\n",
    "        # X.shape -> (batch_size, num_steps , d_model)\n",
    "        # num_steps is the position, num_steps is the index\n",
    "        print('X.shape = ', X.shape)\n",
    "        print('P.shpae = ', self.P.shape)\n",
    "        return X + self.P[:, :X.shape[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fff61d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Part: Transformer Embedding\n",
    "class TransformerEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, max_len, dropout_rate=0.1):\n",
    "        super(TransformerEmbedding, self).__init__()\n",
    "        self.token_embedding = TokenEmbedding(vocab_size, d_model)\n",
    "        self.position_embedding = PositionalEmbedding(max_len, d_model)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    def forward(self, X):\n",
    "        # X -> (batch_size, num_steps)\n",
    "        X = self.token_embedding(X)\n",
    "        # X -> (batch_size, num_steps, d_model)\n",
    "        X = self.position_embedding(X)\n",
    "        return self.dropout(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aed0c281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  torch.Size([3, 4, 128])\n",
      "P.shpae =  torch.Size([1, 15, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试 Embedding\n",
    "X = torch.arange(12).reshape((3, 4))\n",
    "embedding = TransformerEmbedding(15, 128, 15)\n",
    "Y = embedding(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b7d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiHeadAttention 多头注意力(不包含 Dropout)\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, d_model):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_head = d_model // num_heads\n",
    "        self.query_proj = nn.Linear(d_model, d_model)\n",
    "        self.key_proj = nn.Linear(d_model, d_model)\n",
    "        self.value_proj = nn.Linear(d_model, d_model)\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "        self._attention_weights = None\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        # q, k, v.shape -> (batch_size, seq_len, d_model)\n",
    "        batch_size, seq_len, _ = q.shape\n",
    "        # q, k, v 经过 Linear 层\n",
    "        q = self.query_proj(q)\n",
    "        k = self.key_proj(k)\n",
    "        v = self.value_proj(v)\n",
    "        # q, k, v.shape -> (batch_size, seq_len, d_model)\n",
    "        # -> (batch_size, num_heads, seq_len, d_head)\n",
    "        q = q.reshape(batch_size, seq_len, -1, self.d_head).permute(0, 2, 1, 3)\n",
    "        k = k.reshape(batch_size, seq_len, -1, self.d_head).permute(0, 2, 1, 3)\n",
    "        v = v.reshape(batch_size, seq_len, -1, self.d_head).permute(0, 2, 1, 3)\n",
    "        # q, k, v.shape -> (batch_size, num_heads, seq_len, d_head)\n",
    "        # 计算注意力分数\n",
    "        score = q @ k.permute(0, 1, 3, 2) / math.sqrt(self.d_head)\n",
    "        # mask 操作\n",
    "        if mask is not None:\n",
    "            score = score.masked_fill(\n",
    "                mask == 0,\n",
    "                float(\"-inf\")\n",
    "            )\n",
    "        # score -> (batch_size, num_heads, seq_len, seq_len)\n",
    "        self._attention_weights = torch.softmax(score, dim=-1)\n",
    "        # attention_weights -> (batch_size, num_heads, seq_len, seq_len)\n",
    "        output = self._attention_weights @ v\n",
    "        # output.shape -> (batch_size, num_heads, seq_len, d_head)\n",
    "        # -> (batch_size, seq_len, d_model)\n",
    "        output = output.permute(0, 2, 1, 3).reshape(batch_size, seq_len, -1)\n",
    "        output = self.out_proj(output)\n",
    "        return output\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64fc8d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4, 128]),\n",
       " tensor([[[[0.1822, 0.1772, 0.4764, 0.1642],\n",
       "           [0.2799, 0.2984, 0.4217, 0.0000],\n",
       "           [0.4610, 0.5390, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.2176, 0.2830, 0.2426, 0.2568],\n",
       "           [0.3026, 0.3580, 0.3394, 0.0000],\n",
       "           [0.3696, 0.6304, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.1944, 0.2520, 0.2342, 0.3194],\n",
       "           [0.2906, 0.3639, 0.3455, 0.0000],\n",
       "           [0.5404, 0.4596, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.2188, 0.2023, 0.3029, 0.2760],\n",
       "           [0.3124, 0.2421, 0.4456, 0.0000],\n",
       "           [0.4839, 0.5161, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.1371, 0.2103, 0.1460, 0.5067],\n",
       "           [0.2634, 0.4252, 0.3114, 0.0000],\n",
       "           [0.5425, 0.4575, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.3783, 0.1540, 0.2116, 0.2561],\n",
       "           [0.3928, 0.3328, 0.2744, 0.0000],\n",
       "           [0.5859, 0.4141, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.1192, 0.3171, 0.1539, 0.4098],\n",
       "           [0.3427, 0.3355, 0.3218, 0.0000],\n",
       "           [0.4393, 0.5607, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.2961, 0.1229, 0.0950, 0.4860],\n",
       "           [0.3936, 0.3188, 0.2876, 0.0000],\n",
       "           [0.5076, 0.4924, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.1765, 0.1880, 0.3481, 0.2874],\n",
       "           [0.2921, 0.3475, 0.3604, 0.0000],\n",
       "           [0.3542, 0.6458, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.4265, 0.1091, 0.0919, 0.3725],\n",
       "           [0.4743, 0.2109, 0.3148, 0.0000],\n",
       "           [0.3479, 0.6521, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.1537, 0.4138, 0.2051, 0.2273],\n",
       "           [0.2067, 0.4845, 0.3088, 0.0000],\n",
       "           [0.2930, 0.7070, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.4245, 0.3451, 0.1282, 0.1022],\n",
       "           [0.4983, 0.2198, 0.2819, 0.0000],\n",
       "           [0.4585, 0.5415, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.2137, 0.1271, 0.4669, 0.1923],\n",
       "           [0.2953, 0.1897, 0.5150, 0.0000],\n",
       "           [0.6176, 0.3824, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.1347, 0.3747, 0.3262, 0.1644],\n",
       "           [0.2329, 0.2849, 0.4822, 0.0000],\n",
       "           [0.5904, 0.4096, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.2344, 0.1788, 0.2477, 0.3391],\n",
       "           [0.4046, 0.1958, 0.3995, 0.0000],\n",
       "           [0.7025, 0.2975, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0840, 0.2678, 0.2734, 0.3747],\n",
       "           [0.1443, 0.6471, 0.2085, 0.0000],\n",
       "           [0.5169, 0.4831, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.1518, 0.2631, 0.4102, 0.1749],\n",
       "           [0.3555, 0.2641, 0.3804, 0.0000],\n",
       "           [0.4812, 0.5188, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.1342, 0.5260, 0.2271, 0.1126],\n",
       "           [0.3138, 0.2683, 0.4179, 0.0000],\n",
       "           [0.3596, 0.6404, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.2948, 0.2590, 0.1740, 0.2722],\n",
       "           [0.4628, 0.2508, 0.2864, 0.0000],\n",
       "           [0.5279, 0.4721, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.3956, 0.1256, 0.1888, 0.2900],\n",
       "           [0.2737, 0.4437, 0.2826, 0.0000],\n",
       "           [0.6514, 0.3486, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.2776, 0.2547, 0.2558, 0.2119],\n",
       "           [0.2436, 0.3467, 0.4097, 0.0000],\n",
       "           [0.5554, 0.4446, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.2109, 0.3262, 0.2480, 0.2148],\n",
       "           [0.5930, 0.1697, 0.2373, 0.0000],\n",
       "           [0.3278, 0.6722, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.2200, 0.3800, 0.2613, 0.1387],\n",
       "           [0.2087, 0.4790, 0.3122, 0.0000],\n",
       "           [0.5384, 0.4616, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.2081, 0.1406, 0.2839, 0.3675],\n",
       "           [0.3571, 0.3598, 0.2831, 0.0000],\n",
       "           [0.6435, 0.3565, 0.0000, 0.0000],\n",
       "           [1.0000, 0.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试 MultiHead\n",
    "multi_head = MultiHeadAttention(8, 4)\n",
    "# mask -> (batch_size, num_heads, seq_len, seq_len) -> (3, 8, 4, 4)\n",
    "# Y -> (3, 4, 128)\n",
    "# mask 的含义:\n",
    "# 第 i 行的第 j 列为 0  -> 第 i 个词元, 屏蔽第 j 个词元\n",
    "# 但是现实情况中一般是排除无用词元, 所以一般来说都是通过 (n,) 的向量进行拓展的\n",
    "mask = torch.tensor([\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 1, 1, 0],\n",
    "    [1, 1, 0, 0],\n",
    "    [1, 0, 0, 0]\n",
    "])\n",
    "mask = mask.unsqueeze(0).unsqueeze(0).repeat(3, 8, 1, 1)\n",
    "multi_head = MultiHeadAttention(8, 128)\n",
    "Y = multi_head(Y, Y, Y, mask)\n",
    "# (3, 8, 4, 4)\n",
    "Y.shape, multi_head.attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "197a5060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer Norm, 对于维度进行线性变换\n",
    "class LayerNorm(nn.Module):\n",
    "    # eps 用于防止 var = 0\n",
    "    def __init__(self, d_model, eps=1e-12):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta  = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "    def forward(self, X):\n",
    "        # X.shape -> (batch_size, dim)\n",
    "        mean = X.mean(dim=-1, keepdim=True)\n",
    "        var  = X.var(dim=-1,  keepdim=True, unbiased=False)\n",
    "        out = (X - mean) / torch.sqrt(var + self.eps)\n",
    "        out = self.gamma * out + self.beta\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e55cd971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFN 前馈网络\n",
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self, d_model, num_hidden, dropout_rate=0.1):\n",
    "        super(PositionWiseFFN, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden, d_model)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    def forward(self, X):\n",
    "        X = self.dropout(F.relu(self.fc1(X)))\n",
    "        X = self.fc2(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7f74681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Block\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, num_hiddens, dropout_rate=0.1):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(num_heads, d_model)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.ffn = PositionWiseFFN(d_model, num_hiddens)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "    def forward(self, X, mask=None):\n",
    "        # 残差连接\n",
    "        init_X = X\n",
    "        X = self.dropout1(self.attention(X, X, X, mask))\n",
    "        X = self.norm1(X + init_X)\n",
    "        init_X = X\n",
    "        X = self.dropout1(self.ffn(X))\n",
    "        X = self.norm2(X + init_X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f620cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 Encoder 结构\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, max_len, num_heads, num_hiddens, num_layers, dropout_rate=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.embedding = TransformerEmbedding(vocab_size, d_model, max_len, dropout_rate)\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderBlock(d_model, num_heads, num_hiddens, dropout_rate) for _ in range(num_layers)\n",
    "        ])\n",
    "    def forward(self, X, mask=None):\n",
    "        X = self.embedding(X)\n",
    "        for layer in self.layers:\n",
    "            X = layer(X, mask)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf36941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  torch.Size([3, 4, 128])\n",
      "P.shpae =  torch.Size([1, 20, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12).reshape(3, 4)\n",
    "encoder = TransformerEncoder(20, 128, 20, 8, 256, 6)\n",
    "Y = encoder(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27f6798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, num_hiddens, dropout_rate=0.1):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(num_heads, d_model)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.cross_attention = MultiHeadAttention(num_heads, d_model)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.ffn = PositionWiseFFN(d_model, num_hiddens, dropout_rate)\n",
    "        self.norm3 = LayerNorm(d_model)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "    def forward(self, enc_output, X, t_mask=None, s_mask=None):\n",
    "        init_X = X\n",
    "        X = self.dropout1(self.attention(X, X, X, t_mask))\n",
    "        X = self.norm1(X + init_X)\n",
    "        init_X = X\n",
    "        X = self.dropout2(self.cross_attention(X, enc_output, enc_output, s_mask))\n",
    "        X = self.norm2(X + init_X)\n",
    "        init_X = X\n",
    "        X = self.dropout3(self.ffn(X))\n",
    "        X = self.norm3(X + init_X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c58b8724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder 结构\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_heads, num_hiddens, max_len, num_layers, dropout_rate=0.1):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.embedding = TransformerEmbedding(vocab_size, d_model, max_len, dropout_rate)\n",
    "        self.decoder_layers = nn.ModuleList(\n",
    "            [\n",
    "                DecoderBlock(d_model, num_heads, num_hiddens, dropout_rate) for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "    def forward(self, enc_output, X, t_mask=None, s_mask=None):\n",
    "        X = self.embedding(X)\n",
    "        for layer in self.decoder_layers:\n",
    "            X = layer(enc_output, X, t_mask, s_mask)\n",
    "        X = self.fc(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f41fb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  torch.Size([3, 4, 128])\n",
      "P.shpae =  torch.Size([1, 20, 128])\n",
      "X.shape =  torch.Size([3, 4, 128])\n",
      "P.shpae =  torch.Size([1, 20, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[13, 13, 13, 13],\n",
       "        [12, 13,  7, 13],\n",
       "        [13, 13, 13, 13]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试 Decoder\n",
    "# Encoder 输入 X\n",
    "X = torch.arange(12).reshape(3, 4)\n",
    "encoder = TransformerEncoder(20, 128, 20, 8, 256, 6)\n",
    "# Encoder 输出\n",
    "enc_output = encoder(X)\n",
    "\n",
    "DX = torch.arange(12).reshape(3, 4)\n",
    "decoder = TransformerDecoder(20, 128, 8, 256, 20, 6)\n",
    "Out = decoder(enc_output, X)\n",
    "Out = Out.argmax(dim=-1)\n",
    "Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33f3732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfomer\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 src_pad_idx,\n",
    "                 trg_pad_idx,\n",
    "                 enc_voc_size,\n",
    "                 num_heads,\n",
    "                 max_len,\n",
    "                 trg_voc_size,\n",
    "                 d_model,\n",
    "                 ffn_hidden,\n",
    "                 num_layers,\n",
    "                 dropout_rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = TransformerEncoder(enc_voc_size, d_model, \n",
    "                                          max_len, num_heads, \n",
    "                                          ffn_hidden, num_layers, dropout_rate)\n",
    "        self.decoder = TransformerDecoder(trg_voc_size, d_model, num_heads,ffn_hidden,\n",
    "                                          max_len, num_layers, dropout_rate)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "    def make_pad_mask(self, q, k, pad_idx_q, pad_idx_k):\n",
    "        # 注意此时 q, k 长度 -> seq_len\n",
    "        # 最终需要比较的序列 -> (batch_size, num_heads, seq_len, seq_len)\n",
    "        # 所以这里可以使用掩码, 并且涉及到注意力分数的计算只需要考虑 q, k 即可\n",
    "        len_q, len_k = q.size(1), k.size(1)\n",
    "        q = q.ne(pad_idx_q).unsqueeze(1).unsqueeze(3)\n",
    "        q = q.repeat(1, 1, 1, len_k)\n",
    "        k = k.ne(pad_idx_k).unsqueeze(1).unsqueeze(2)\n",
    "        k = k.repeat(1, 1, len_q, 1)\n",
    "        mask = q & k\n",
    "        return mask\n",
    "    def make_causal_mask(self, q, k):\n",
    "        len_q, len_k = q.size(1), k.size(1)\n",
    "        mask = torch.tril(torch.ones(len_q, len_k)).type(torch.float32)\n",
    "        return mask\n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.make_pad_mask(src, src, self.src_pad_idx, self.src_pad_idx)\n",
    "        trg_mask = self.make_pad_mask(trg, trg, self.trg_pad_idx, self.trg_pad_idx)*self.make_causal_mask(trg, trg)\n",
    "        enc = self.encoder(src, src_mask)\n",
    "        out = self.decoder(enc, trg, trg_mask, src_mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c8a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0.],\n",
       "         [1., 1., 0.],\n",
       "         [1., 1., 1.]]),\n",
       " tensor([[ True, False, False],\n",
       "         [ True,  True, False],\n",
       "         [ True,  True,  True]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.tril(torch.ones(3, 3))\n",
    "mask "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
